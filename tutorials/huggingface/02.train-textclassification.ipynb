{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train HuggingFace text classifiation Models with PyTorch\n",
    "\n",
    "description: train single-node, including single-node multi-gpu, pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorboard azureml-tensorboard gitpython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import git\n",
    "from pathlib import Path\n",
    "\n",
    "# get root of git repo\n",
    "prefix = Path(git.Repo(\".\", search_parent_directories=True).working_tree_dir)\n",
    "\n",
    "# training script\n",
    "source_dir = prefix.joinpath(\n",
    "    \"code\", \"train\", \"huggingface\", \"classification\"\n",
    ")\n",
    "script_name = \"train.py\"\n",
    "\n",
    "# environment file\n",
    "environment_file = prefix.joinpath(\"environments\", \"huggingface-stc.yml\")\n",
    "\n",
    "# azure ml settings\n",
    "environment_name = \"hf-classification\"\n",
    "experiment_name = \"hf-classification\"\n",
    "cluster_name = \"gpu-K80-2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create environment\n",
    "\n",
    "Define a conda environment YAML file with your training script dependencies and create an Azure ML environment. The dependencies for this tutorial include **torch**, **torchvision**, and **pytorch-lightning**.\n",
    "\n",
    "Since this example is for GPU training, you will need to specify a GPU base image that has the necessary dependencies. Azure ML maintains a set of base images published on Microsoft Container Registry (MCR) that you can use, see the [Azure/AzureML-Containers](https://github.com/Azure/AzureML-Containers) GitHub repo for more information.\n",
    "\n",
    "Azure ML will build a conda environment with the dependencies you specified in your .yml file on the base image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "env = Environment.from_conda_specification(environment_name, environment_file)\n",
    "\n",
    "# specify a GPU base image\n",
    "env.docker.enabled = True\n",
    "env.docker.base_image = (\n",
    "    \"mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.2-cudnn8-ubuntu18.04\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can just capture all your dependencies directly in a custom Docker image or Dockerfile, and create your environment from that. For more information, see [Train with custom image](https://docs.microsoft.com/azure/machine-learning/how-to-train-with-custom-image)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure and run training job\n",
    "Create a ScriptRunConfig to specify the training script & arguments, environment, and cluster to run on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azureml.core import ScriptRunConfig, Experiment\n",
    "\n",
    "cluster = ws.compute_targets[cluster_name]\n",
    "\n",
    "src = ScriptRunConfig(\n",
    "    source_directory=source_dir,\n",
    "    script=script_name,\n",
    "    arguments=[\"--model_name_or_path\", \"bert-base-cased \",\n",
    "               \"--task_name\", \"MRPC\",\n",
    "               \"--do_train\", \"\",\n",
    "               \"--do_eval\", \"\",\n",
    "               \"--max_seq_length\", 128,\n",
    "               \"--per_device_train_batch_size\", 32,\n",
    "               \"--learning_rate\", 2e-5,\n",
    "               \"--num_train_epochs\", 3,\n",
    "               \"--output_dir\", \"./output\"\n",
    "               ],\n",
    "    compute_target=cluster,\n",
    "    environment=env,\n",
    ")\n",
    "run = Experiment(ws, experiment_name).submit(src)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}