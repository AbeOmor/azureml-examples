{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy to Triton Inference Server locally\n",
    "\n",
    "description: (preview) deploy an image classification model trained on densenet locally via Triton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that this Public Preview release is subject to the [Supplemental Terms of Use for Microsoft Azure Previews](https://azure.microsoft.com/support/legal/preview-supplemental-terms/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: nvidia-pyindex in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (1.0.5)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already up-to-date: tritonclient in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (2.4.0)\n",
      "Requirement already satisfied, skipping upgrade: python-rapidjson>=0.9.1 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from tritonclient) (0.9.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.19.1 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from tritonclient) (1.19.4)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: azureml-core==1.19.0a1 from file:///home/gopalv/azureml-examples/tutorials/deploy-triton/azureml_core-1.19.0a1-py3-none-any.whl in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (1.19.0a1)\n",
      "Requirement already satisfied: docker in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (4.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (2.8.1)\n",
      "Requirement already satisfied: contextlib2 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (0.6.0.post1)\n",
      "Requirement already satisfied: urllib3>=1.23 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (1.25.10)\n",
      "Requirement already satisfied: adal>=1.2.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (1.2.4)\n",
      "Requirement already satisfied: azure-mgmt-authorization<1.0.0,>=0.40.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (0.60.0)\n",
      "Requirement already satisfied: azure-common>=1.1.12 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (1.1.25)\n",
      "Requirement already satisfied: cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.* in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (3.0)\n",
      "Requirement already satisfied: backports.tempfile in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (1.0)\n",
      "Requirement already satisfied: pytz in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (2020.1)\n",
      "Requirement already satisfied: azure-mgmt-containerregistry>=2.0.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (2.8.0)\n",
      "Requirement already satisfied: azure-graphrbac<1.0.0,>=0.40.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (0.61.1)\n",
      "Requirement already satisfied: PyJWT<2.0.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (1.7.1)\n",
      "Requirement already satisfied: azure-mgmt-storage<16.0.0,>=1.5.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (11.1.0)\n",
      "Requirement already satisfied: SecretStorage in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (3.1.2)\n",
      "Requirement already satisfied: azure-mgmt-resource<15.0.0,>=1.2.1 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (10.1.0)\n",
      "Requirement already satisfied: pathspec in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (0.8.0)\n",
      "Requirement already satisfied: ndg-httpsclient in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (0.5.1)\n",
      "Requirement already satisfied: msrestazure>=0.4.33 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (0.6.4)\n",
      "Requirement already satisfied: jmespath in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (0.10.0)\n",
      "Requirement already satisfied: jsonpickle in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (1.4.1)\n",
      "Requirement already satisfied: requests>=2.19.1 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (2.24.0)\n",
      "Requirement already satisfied: pyopenssl<20.0.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (19.1.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.15.35 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (0.16.10)\n",
      "Requirement already satisfied: azure-mgmt-keyvault<7.0.0,>=0.40.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (2.2.0)\n",
      "Requirement already satisfied: msrest>=0.5.1 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (0.6.18)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from docker->azureml-core==1.19.0a1) (1.15.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from docker->azureml-core==1.19.0a1) (0.57.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==1.19.0a1) (1.14.1)\n",
      "Requirement already satisfied: backports.weakref in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from backports.tempfile->azureml-core==1.19.0a1) (1.0.post1)\n",
      "Requirement already satisfied: jeepney>=0.4.2 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from SecretStorage->azureml-core==1.19.0a1) (0.4.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.1 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from ndg-httpsclient->azureml-core==1.19.0a1) (0.4.8)\n",
      "Requirement already satisfied: importlib-metadata in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from jsonpickle->azureml-core==1.19.0a1) (1.7.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from requests>=2.19.1->azureml-core==1.19.0a1) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from requests>=2.19.1->azureml-core==1.19.0a1) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from requests>=2.19.1->azureml-core==1.19.0a1) (2020.6.20)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\" in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from ruamel.yaml>=0.15.35->azureml-core==1.19.0a1) (0.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from msrest>=0.5.1->azureml-core==1.19.0a1) (1.3.0)\n",
      "Requirement already satisfied: isodate>=0.6.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from msrest>=0.5.1->azureml-core==1.19.0a1) (0.6.0)\n",
      "Requirement already satisfied: pycparser in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from cffi!=1.11.3,>=1.8->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==1.19.0a1) (2.20)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from importlib-metadata->jsonpickle->azureml-core==1.19.0a1) (3.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.1->azureml-core==1.19.0a1) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nvidia-pyindex\n",
    "!pip install --upgrade tritonclient\n",
    "!pip install azureml_core-1.19.0a1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Workspace.create(name='Inference-PM-AML-Workspace', subscription_id='92c76a2f-0e1c-4216-b65e-abf7a3f34c1e', resource_group='Inference-PM')"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download model\n",
    "\n",
    "It's important that your model have this directory structure for Triton Inference Server to be able to load it. [Read more about the directory structure that Triton expects](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/model_repository.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "successfully downloaded model: densenet_onnx\n",
      "successfully downloaded model: bidaf-9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from src.model_utils import download_triton_models, delete_triton_models\n",
    "\n",
    "prefix = Path(\".\")\n",
    "download_triton_models(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register model\n",
    "\n",
    "A registered model is a logical container stored in the cloud, containing all files located at `model_path`, which is associated with a version number and other metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Registering model densenet-onnx-example\n",
      "Model(workspace=Workspace.create(name='Inference-PM-AML-Workspace', subscription_id='92c76a2f-0e1c-4216-b65e-abf7a3f34c1e', resource_group='Inference-PM'), name=densenet-onnx-example, id=densenet-onnx-example:7, version=7, tags={'area': 'Image classification', 'type': 'classification'}, properties={})\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model_path = \"models\"\n",
    "\n",
    "model = Model.register(\n",
    "    model_path=model_path,\n",
    "    model_name=\"densenet-onnx-example\",\n",
    "    tags={\"area\": \"Image classification\", \"type\": \"classification\"},\n",
    "    description=\"Image classification trained on Imagenet Dataset\",\n",
    "    workspace=ws,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy webservice\n",
    "\n",
    "In this case we deploy to the local compute, but for other options, see [our documentation](https://docs.microsoft.com/azure/machine-learning/how-to-deploy-and-where?tabs=azcli).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning, custom base image or base dockerfile detected without a specified `inferencing_stack_version`. Please set environment.inferencing_stack_version='latest'\n",
      "Downloading model densenet-onnx-example:7 to /tmp/azureml_tsae_34e/densenet-onnx-example/7\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry inferencepmaef584480.azurecr.io\n",
      "Logging into Docker registry inferencepmaef584480.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM inferencepmaef584480.azurecr.io/azureml/azureml_930c481407be9ccaddfb266acde89404\n",
      " ---> 3aece98eaff6\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> 5d041ba38b0b\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjkyYzc2YTJmLTBlMWMtNDIxNi1iNjVlLWFiZjdhM2YzNGMxZSIsInJlc291cmNlR3JvdXBOYW1lIjoiaW5mZXJlbmNlLXBtIiwiYWNjb3VudE5hbWUiOiJpbmZlcmVuY2UtcG0tYW1sLXdvcmtzcGFjZSIsIndvcmtzcGFjZUlkIjoiODI0NDI5MGEtMzUwNi00MDEyLTgxNjAtOGQ4NjcwMzMzZTE5In0sIm1vZGVscyI6e30sIm1vZGVsc0luZm8iOnt9fQ== | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in ef9d6e1a2e45\n",
      " ---> c69319802a5a\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmpaj4taffb.py' /var/azureml-app/main.py\n",
      " ---> Running in 626e93136fbe\n",
      " ---> 6bbd4c554e31\n",
      "Step 5/5 : CMD [\"bash\",\"-c\",\"source activate '/opt/miniconda'; export AZUREML_CONDA_ENVIRONMENT_PATH=${AZUREML_CONDA_ENVIRONMENT_PATH:=$CONDA_PREFIX}; exec 'runsvdir' '/var/runit'\"]\n",
      " ---> Running in 96ce7459771d\n",
      " ---> 490b9b33a8a6\n",
      "Successfully built 490b9b33a8a6\n",
      "Successfully tagged triton-densenet-onnx-local22573:latest\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:6789\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import LocalWebservice\n",
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.model import InferenceConfig\n",
    "from random import randint\n",
    "\n",
    "service_name = \"triton-densenet-onnx-local\" + str(randint(10000, 99999))\n",
    "\n",
    "\n",
    "env = Environment(\"triton-tutorial\")\n",
    "env.docker.base_image = None\n",
    "env.docker.base_dockerfile = \"Dockerfile\"\n",
    "env.python.user_managed_dependencies = True\n",
    "env.python.interpreter_path = \"/opt/miniconda/bin/python\"\n",
    "\n",
    "env.environment_variables[\"WORKER_COUNT\"] = \"1\"\n",
    "\n",
    "inference_config = InferenceConfig(\n",
    "    # this entry script is where we dispatch a call to the Triton server\n",
    "    source_directory=\"src\",\n",
    "    entry_script=\"score_densenet.py\",\n",
    "    environment=env,\n",
    ")\n",
    "\n",
    "config = LocalWebservice.deploy_configuration(port=6789)\n",
    "\n",
    "service = Model.deploy(\n",
    "    workspace=ws,\n",
    "    name=service_name,\n",
    "    models=[model],\n",
    "    inference_config=inference_config,\n",
    "    deployment_config=config,\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the webservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "84 : PEACOCK\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\"Content-Type\": \"application/octet-stream\"}\n",
    "\n",
    "test_sample = requests.get(\"https://aka.ms/peacock-pic\", allow_redirects=True).content\n",
    "resp = requests.post(service.scoring_uri, data=test_sample, headers=headers)\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the webservice and the downloaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Container has been successfully cleaned up.\nsuccessfully deleted model: densenet_onnx\nsuccessfully deleted model: bidaf-9\n"
     ]
    }
   ],
   "source": [
    "service.delete()\n",
    "delete_triton_models(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "Try changing the deployment configuration to [deploy to Azure Kubernetes Service](https://docs.microsoft.com/azure/machine-learning/how-to-deploy-azure-kubernetes-service?tabs=python) for higher availability and better scalability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('azureml': conda)",
   "metadata": {
    "interpreter": {
     "hash": "53514593536e52de022f29ef618678eddccd581b6db5dc532e9838fb19203af5"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "name": "deploy-densenet-local",
  "task": "Use the high-performance Triton Inference Server with Azure Machine Learning"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}